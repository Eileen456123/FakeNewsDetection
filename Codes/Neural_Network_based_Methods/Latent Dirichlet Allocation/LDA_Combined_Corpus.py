from gensim.models import LdaModel
from keras.preprocessing.text import Tokenizer
from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer
from sklearn.decomposition import TruncatedSVD
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import Normalizer
from sklearn.neighbors import KNeighborsClassifier
import pickle
import numpy as np
from gensim import corpora, models, similarities, matutils
import gensim
from gensim.utils import simple_preprocess
from gensim.parsing.preprocessing import STOPWORDS
import nltk

import logging
import itertools

from GensimCorpus import GensimCorpus

logging.basicConfig(format='%(levelname)s : %(message)s', level=logging.INFO)
logging.root.level = logging.INFO

pickle_load=open('pickle_cleanXy_fulltrain_Guardian_Nyt_binary_shuffled.pickle','rb')
X,y=pickle.load(pickle_load)

dataset=np.concatenate((X,y),axis=1)

stoplist = set('for a of the and to in'.split())
texts = [[word for word in document.lower().split() if word not in stoplist]
         for document in dataset[:,0]]

from collections import defaultdict
frequency = defaultdict(int)
for text in texts:
    for token in text:
       #token=nltk.re.sub(r"[0-9]+","",token)
       if(nltk.re.search(r"[a-zA-Z]",token)):
           frequency[token]+=1

texts = [[token for token in text if frequency[token] > 1]
         for text in texts]

#print(texts)

dictionary = corpora.Dictionary(texts)
dictionary.save('lda/token_Dict_2.dict')
#print(dictionary)

'''
dictionary=gensim.corpora.Dictionary.load('lda/token_Dict_2.dict')
print(dictionary.token2id)'''

corpus = [dictionary.doc2bow(text) for text in texts]
corpora.MmCorpus.serialize('lda/doc2bow_corpus_2.mm', corpus)

'''
mm_corpus = gensim.corpora.MmCorpus('lda/doc2bow_corpus_2.mm')
#print(next(iter(mm_corpus)))'''

lda_model = gensim.models.LdaModel(mm_corpus, num_topics=10, id2word=dictionary, passes=20)

lda_model.save('lda/\lda_model_2.model')

'''lda_model =  models.LdaModel.load('lda/radim_lda_model_2.model')'''
lda_model.show_topics()

##############  VISUALIZING with PyLDAvis ###################################
import pyLDAvis.gensim
lda_vis = gensim.models.ldamodel.LdaModel.load('lda/radim_lda_model_2.model')
lda_display = pyLDAvis.gensim.prepare(lda_vis, mm_corpus, dictionary)
#pyLDAvis.display(lda_display)
pyLDAvis.save_html(lda_display, 'lda/pyLDAvis/pyLDAvis_LDA1.html')
############################################################################

# Checking a data
d0=dataset[0][0]
print(d0)
bow=dictionary.doc2bow([word for word in d0.lower().split() if word not in stoplist])
print([(dictionary[id], count) for id, count in bow])
# transform into LDA space
lda_vector = lda_model[bow]
print(lda_vector)
#print(np.argmax(lda_vector,axis=0))
print(lda_model.print_topic(max(lda_vector, key=lambda item: item[1])[0]))
for vec in lda_vector:
    if(vec[1]>0.1):
        print(str(vec[0]))
