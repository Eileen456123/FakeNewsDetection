{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of DistilBERT_CombinedCorpus_simpleTransformer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjqhBcWD1xnh"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLkvT6LJ-6b9"
      },
      "source": [
        "!pip install -q keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGfdUvaI_L1z"
      },
      "source": [
        "!pip install -q pydrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNSCcGrX-9W6"
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcQJ88xv-_AL"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mdKhhz9_BET"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poFPYutz_C_r"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkMg-6_Y_I4b"
      },
      "source": [
        "!pip install simpletransformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HG8PFa1t_JHb"
      },
      "source": [
        "project_path = '/content/drive/My Drive/Fake News Detection'## we will store our data in this drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRYBsbPp_NTT"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_total=pd.read_csv(os.path.join(project_path,'fulltrain_Guardian_Nyt_binary_shuffled.csv'),delimiter=',')\n",
        "\n",
        "\n",
        "df_train, df_test = train_test_split(df_total, test_size=0.2, random_state=42, shuffle=True)\n",
        "\n",
        "#statement=dataset.iloc[:,2:3].values\n",
        "#statement=statement.lower()\n",
        "texts_train=[]\n",
        "texts_train=df_train['Statement']#####################################\n",
        "#print(texts)\n",
        "#texts=texts.tolist()\n",
        "#statement=np.array(statement,dtype='str')\n",
        "label_train=df_train['Label']\n",
        "#print(label)\n",
        "\n",
        "#texts=texts.map(lambda x: clean_text(x)) ################################\n",
        "\n",
        "X_train=texts_train.astype(str).values\n",
        "X_train=np.reshape(X_train,(-1,1))\n",
        "#print(X)\n",
        "\n",
        "#label=label.astype(int).values\n",
        "#labelEncoder=LabelEncoder()\n",
        "#encoded_label=labelEncoder.fit_transform(label)\n",
        "\n",
        "label_train=label_train.astype(int).values\n",
        "y_train=np.reshape(label_train,(-1,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFeRV1Ze_PV8"
      },
      "source": [
        "#df_test=pd.read_csv(os.path.join(project_path,'LiarTest.csv'),delimiter=',')\n",
        "\n",
        "texts_test=[]\n",
        "texts_test=df_test['Statement']#####################################\n",
        "label_test=df_test['Label']\n",
        "#print(label)\n",
        "\n",
        "#texts=texts.map(lambda x: clean_text(x)) ################################\n",
        "\n",
        "X_test=texts_test.astype(str).values\n",
        "X_test=np.reshape(X_test,(-1,1))\n",
        "#print(X)\n",
        "\n",
        "label_test=label_test.astype(int).values\n",
        "y_test=np.reshape(label_test,(-1,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqafQCmHAHpU"
      },
      "source": [
        "sentences = X_train[:,0]\n",
        "print(sentences[0])\n",
        "labels = y_train[:, 0]\n",
        "#labels = y_train\n",
        "print(labels[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyuf8-2xDUh7"
      },
      "source": [
        "VALIDATION_SPLIT = 0.2\n",
        "\n",
        "nb_validation_samples = int(VALIDATION_SPLIT * sentences.shape[0])\n",
        "\n",
        "x_train = sentences[:-nb_validation_samples]\n",
        "y_train = labels[:-nb_validation_samples]\n",
        "x_val = sentences[-nb_validation_samples:]\n",
        "y_val = labels[-nb_validation_samples:]\n",
        "\n",
        "print(x_train[0])\n",
        "print(x_val[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AA5EtjStDYLT"
      },
      "source": [
        "import pandas as pd\n",
        "ll=[]\n",
        "for i in range(len(x_train)):\n",
        "  ll.append([x_train[i],y_train[i]])\n",
        "\n",
        "train_df = pd.DataFrame(ll,columns=['text','labels'])\n",
        "\n",
        "\n",
        "ll=[]\n",
        "for i in range(len(x_val)):\n",
        "  ll.append([x_val[i],y_val[i]])\n",
        "\n",
        "val_df = pd.DataFrame(ll,columns=['text','labels'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PBNHFuYDbB8"
      },
      "source": [
        "sentences_test = X_test[:,0]\n",
        "print(sentences_test[0])\n",
        "labels_test = y_test[:, 0]\n",
        "#labels = y_train\n",
        "print(labels_test[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjWZObxtDcaT"
      },
      "source": [
        "ll=[]\n",
        "for i in range(len(sentences_test)):\n",
        "  ll.append([sentences_test[i],labels_test[i]])\n",
        "\n",
        "test_df = pd.DataFrame(ll,columns=['text','labels'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gzI-bIBDgbT"
      },
      "source": [
        "print('Training sample: ' + str(len(train_df['text'])))\n",
        "print('Validation sample: ' + str(len(val_df['text'])))\n",
        "print('Testing sample: ' + str(len(test_df['text'])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gBHbO_DDkp7"
      },
      "source": [
        "model_type = \"distilbert\"\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "\n",
        "train_args = {\n",
        "    \"reprocess_input_data\": True,\n",
        "    \"overwrite_output_dir\": True,\n",
        "    \"use_cached_eval_features\": True,\n",
        "    \"output_dir\": \"/content/drive/My Drive/Fake News Detection/LIAR/DistilBERT/\"+model_type,\n",
        "    \"best_model_dir\": \"/content/drive/My Drive/Fake News Detection/LIAR/DistilBERT/\"+model_type+\"/best_model\",\n",
        "    \"use_early_stopping\": False,\n",
        "    \"early_stopping_delta\": 0.0,\n",
        "    \"early_stopping_metric\": \"eval_loss\",\n",
        "    \"early_stopping_metric_minimize\" : True,\n",
        "    \"early_stopping_patience\" : 2,\n",
        "    \"evaluate_during_training\": True,\n",
        "    \"gradient_accumulation_steps\": 1,\n",
        "    \"max_seq_length\": 300, \n",
        "    \"num_train_epochs\": 5, #10,\n",
        "    \"evaluate_during_training\": True,\n",
        "    \"evaluate_during_training_steps\": 32, #64,\n",
        "    \"wandb_project\": \"Fake News Liar_1 Bert\",\n",
        "    \"wandb_kwargs\": {\"name\": model_name},\n",
        "    \"save_model_every_epoch\": False,\n",
        "    \"save_eval_checkpoints\": False,\n",
        "    \"train_batch_size\": 32, #64\n",
        "    \"eval_batch_size\": 32, #64\n",
        "    \"evaluate_during_training_verbose\" : True,\n",
        "    \"use_early_stopping\": True\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iivYRdGqDrED"
      },
      "source": [
        "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
        "#import pandas as pd\n",
        "\n",
        "# Create a ClassificationModel\n",
        "model = ClassificationModel(model_type, model_name, args=train_args)\n",
        "\n",
        "# Train the model\n",
        "model.train_model(train_df,eval_df = val_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3vRmmu-MAk5"
      },
      "source": [
        "result, model_outputs, wrong_predictions = model.eval_model(test_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EXpngKNMTma"
      },
      "source": [
        "predictions, raw_outputs = model.predict(test_df['text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GUg4jUGMVvo"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(test_df['labels'],predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLJHkZozNHkk"
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "print(precision_recall_fscore_support(test_df['labels'],predictions, average='weighted'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUGJHY6n8gUi"
      },
      "source": [
        "import pickle\n",
        "with open(project_path+'/Saved Models/DistilBERT_CombinedCorpus_simpleTransformer_pickle.pickle', 'wb') as f:\n",
        "  pickle.dump((test_df['labels'],predictions),f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHJUB6XS8rtk"
      },
      "source": [
        "import pickle\n",
        "with open(project_path+'/Saved Models/DistilBERT_CombinedCorpus_simpleTransformer_pickle.pickle', 'rb') as f:\n",
        "  y_true, y_pred = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNBfPSYE8vwI"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(y_true, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}