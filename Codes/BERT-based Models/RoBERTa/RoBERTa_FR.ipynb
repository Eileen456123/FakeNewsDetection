{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RoBERTa_FR.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"MpxvQ14HFYM1"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"utYxkMR9F0wq"},"source":["!pip install -q pydrive"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OIJwvszjF4AZ"},"source":["from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WxE-L4LS3v5I"},"source":["import tensorflow as tf\n","\n","# Get the GPU device name.\n","device_name = tf.test.gpu_device_name()\n","\n","# The device name should look like the following:\n","if device_name == '/device:GPU:0':\n","    print('Found GPU at: {}'.format(device_name))\n","else:\n","    raise SystemError('GPU device not found')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y8N8IE0Z30_Y"},"source":["import torch\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6-PaQ17P36m8"},"source":["!pip install transformers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SCBxNisC4Ga-"},"source":["!pip install simpletransformers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QsmkWna44Fdc"},"source":["project_path='/content/drive/My Drive/Fake News/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7HLkBop16E6J"},"source":["import numpy as np\n","import pandas as pd\n","\n","dataset = pd.read_csv(project_path+'fake_or_real_news.csv')\n","print(dataset.shape)\n","\n","texts=[]\n","texts=dataset['text']#####################################\n","label=dataset['label']\n","\n","from sklearn.preprocessing import LabelEncoder\n","labelEncoder=LabelEncoder()\n","encoded_label=labelEncoder.fit_transform(label)\n","y=np.reshape(encoded_label,(-1,1))\n","\n","\n","#X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n","\n","training_size=int(0.8*dataset.shape[0])\n","print(dataset.shape[0],training_size)\n","data_train=dataset[:training_size]['text']\n","y_train_val=y[:training_size]\n","data_test=dataset[training_size:]['text']\n","y_test=y[training_size:]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7cyxuaPe4bWT"},"source":["sentences = data_train\n","print(sentences)\n","labels = y_train_val[:,0]\n","#labels = y_train\n","print(labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ITPUk5tQ4QvR"},"source":["print('Max sentence length: ', max([len(sen.split(' ')) for sen in sentences]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"01W44l6K7N_p"},"source":["print(sentences[:1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"33g5TEkldF8K"},"source":["TRAIN_SPLIT = 0.8\n","\n","nb_train_samples = int(TRAIN_SPLIT * sentences.shape[0])\n","\n","x_train = np.array(sentences[:nb_train_samples])\n","y_train = np.array(labels[:nb_train_samples])\n","x_val = np.array(sentences[nb_train_samples:])\n","y_val = np.array(labels[nb_train_samples:])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_fzadJpd7gaw"},"source":["import pandas as pd\n","ll=[]\n","for i in range(len(x_train)):\n","  ll.append([x_train[i],y_train[i]])\n","\n","train_df = pd.DataFrame(ll,columns=['text','labels'])\n","\n","\n","ll=[]\n","for i in range(len(x_val)):\n","  ll.append([x_val[i],y_val[i]])\n","\n","val_df = pd.DataFrame(ll,columns=['text','labels'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"frj6xSKu_w2y"},"source":["sentences_test = np.array(data_test)\n","print(sentences_test[0])\n","labels_test = y_test[:, 0]\n","#labels = y_train\n","print(labels_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iU-lAE0N8Uc0"},"source":["ll=[]\n","for i in range(len(sentences_test)):\n","  ll.append([sentences_test[i],labels_test[i]])\n","\n","test_df = pd.DataFrame(ll,columns=['text','labels'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IHPzg87wemnb"},"source":["print('Training sample: ' + str(len(train_df['text'])))\n","print('Validation sample: ' + str(len(val_df['text'])))\n","print('Testing sample: ' + str(len(test_df['text'])))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"evd3WkX45UPc"},"source":["model_type = \"roberta\"\n","model_name = \"roberta-base\"\n","\n","train_args = {\n","    \"reprocess_input_data\": True,\n","    \"overwrite_output_dir\": True,\n","    \"use_cached_eval_features\": True,\n","    \"output_dir\": \"/content/drive/My Drive/Fake News/Transformer/output/\"+model_type,\n","    \"best_model_dir\": \"/content/drive/My Drive/Fake News/Transformer/output/\"+model_type+\"/best_model\",\n","    \"use_early_stopping\": False,\n","    \"early_stopping_delta\": 0.0,\n","    \"early_stopping_metric\": \"eval_loss\",\n","    \"early_stopping_metric_minimize\" : True,\n","    \"early_stopping_patience\" : 2,\n","    \"evaluate_during_training\": True,\n","    \"max_seq_length\": 512,\n","    \"num_train_epochs\": 10,\n","    \"evaluate_during_training_steps\": 64,\n","    \"wandb_project\": \"Fake News FR_1 RoBerta\",\n","    \"wandb_kwargs\": {\"name\": model_name},\n","    \"save_model_every_epoch\": False,\n","    \"save_eval_checkpoints\": False,\n","    \"train_batch_size\": 64,\n","    \"eval_batch_size\": 64,\n","    \"evaluate_during_training_verbose\" : True\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Cb8Nn9-65k6"},"source":["from simpletransformers.classification import ClassificationModel, ClassificationArgs\n","#import pandas as pd\n","\n","train_args[\"max_seq_length\"] = 300\n","train_args[\"train_batch_size\"] = 32\n","train_args[\"gradient_accumulation_steps\"] = 1\n","train_args[\"evaluate_during_training\"] = True\n","train_args[\"num_train_epochs\"] = 10\n","train_args[\"use_early_stopping\"] = True\n","\n","\n","# Create a ClassificationModel\n","model = ClassificationModel(model_type, model_name, args=train_args)\n","\n","# Train the model\n","model.train_model(train_df,eval_df = val_df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CJhJrQnc-8T1"},"source":["result, model_outputs, wrong_predictions = model.eval_model(test_df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sbTJrCnfWssH"},"source":["predictions, raw_outputs = model.predict(test_df['text'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tTzHVMsxXTzG"},"source":["from sklearn.metrics import accuracy_score\n","print(accuracy_score(test_df['labels'],predictions))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LgwrfpF_YDuk"},"source":["import pickle\n","with open(project_path+'Predictions/pickle_Pred_Roberta_1_FR.pickle', 'wb') as f:\n","  pickle.dump((test_df['labels'],predictions),f)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hQdU2sX_ZKFa"},"source":["import pickle\n","with open(project_path+'Predictions/pickle_Pred_Roberta_1_FR.pickle', 'rb') as f:\n","  y_true, y_pred = pickle.load(f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-tphUDGNZVIF"},"source":["from sklearn.metrics import accuracy_score\n","print(accuracy_score(y_true, y_pred))"],"execution_count":null,"outputs":[]}]}